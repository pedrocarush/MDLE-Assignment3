{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import SEEK_CUR\n",
    "import os.path as path\n",
    "import pandas as pd\n",
    "import gzip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_energy_dataset = 'ca-HepPh.txt.gz'\n",
    "facebook_dataset = 'facebook_combined.txt.gz'\n",
    "pathways_dataset = 'PP-Pathways_ppi.csv.gz'\n",
    "data_folder = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset: str, data_folder: str = data_folder) -> pd.DataFrame:\n",
    "    pt = path.join(data_folder, dataset)\n",
    "    \n",
    "    if dataset == 'ca-HepPh.txt.gz':\n",
    "        with gzip.open(pt, 'rb') as f:\n",
    "            c = f.read(1)\n",
    "            while c == b'#':\n",
    "                f.readline()\n",
    "                c = f.read(1)\n",
    "            f.seek(-1, SEEK_CUR)\n",
    "            return pd.read_csv(f, sep='\\t', header=None)\n",
    "        \n",
    "    elif dataset == 'facebook_combined.txt.gz':\n",
    "        return pd.read_csv(pt, sep=' ', header=None)\n",
    "\n",
    "    return pd.read_csv(pt, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(facebook_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters_ideal = 8    # TODO: choose an appropriate value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 58.0 GiB for an array with shape (88234, 88234) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcluster\u001b[39;00m \u001b[39mimport\u001b[39;00m SpectralClustering\n\u001b[0;32m----> 3\u001b[0m SpectralClustering(n_clusters_ideal, eigen_solver\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlobpcg\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(dataset)\n",
      "File \u001b[0;32m~/ua/4-2/mdle/venv/lib/python3.10/site-packages/sklearn/cluster/_spectral.py:745\u001b[0m, in \u001b[0;36mSpectralClustering.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    743\u001b[0m         params[\u001b[39m\"\u001b[39m\u001b[39mdegree\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdegree\n\u001b[1;32m    744\u001b[0m         params[\u001b[39m\"\u001b[39m\u001b[39mcoef0\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef0\n\u001b[0;32m--> 745\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maffinity_matrix_ \u001b[39m=\u001b[39m pairwise_kernels(\n\u001b[1;32m    746\u001b[0m         X, metric\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maffinity, filter_params\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams\n\u001b[1;32m    747\u001b[0m     )\n\u001b[1;32m    749\u001b[0m random_state \u001b[39m=\u001b[39m check_random_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n\u001b[1;32m    750\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels_ \u001b[39m=\u001b[39m spectral_clustering(\n\u001b[1;32m    751\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maffinity_matrix_,\n\u001b[1;32m    752\u001b[0m     n_clusters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_clusters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    759\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m    760\u001b[0m )\n",
      "File \u001b[0;32m~/ua/4-2/mdle/venv/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:2205\u001b[0m, in \u001b[0;36mpairwise_kernels\u001b[0;34m(X, Y, metric, filter_params, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   2202\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2203\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown kernel \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m metric)\n\u001b[0;32m-> 2205\u001b[0m \u001b[39mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/ua/4-2/mdle/venv/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1579\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1576\u001b[0m X, Y, dtype \u001b[39m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[1;32m   1578\u001b[0m \u001b[39mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 1579\u001b[0m     \u001b[39mreturn\u001b[39;00m func(X, Y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m   1581\u001b[0m \u001b[39m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[1;32m   1582\u001b[0m fd \u001b[39m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[0;32m~/ua/4-2/mdle/venv/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1314\u001b[0m, in \u001b[0;36mrbf_kernel\u001b[0;34m(X, Y, gamma)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[39mif\u001b[39;00m gamma \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1312\u001b[0m     gamma \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m-> 1314\u001b[0m K \u001b[39m=\u001b[39m euclidean_distances(X, Y, squared\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1315\u001b[0m K \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39m-\u001b[39mgamma\n\u001b[1;32m   1316\u001b[0m np\u001b[39m.\u001b[39mexp(K, K)  \u001b[39m# exponentiate K in-place\u001b[39;00m\n",
      "File \u001b[0;32m~/ua/4-2/mdle/venv/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:328\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[39mif\u001b[39;00m Y_norm_squared\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m (\u001b[39m1\u001b[39m, Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[1;32m    323\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    324\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIncompatible dimensions for Y of shape \u001b[39m\u001b[39m{\u001b[39;00mY\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    325\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mY_norm_squared of shape \u001b[39m\u001b[39m{\u001b[39;00moriginal_shape\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         )\n\u001b[0;32m--> 328\u001b[0m \u001b[39mreturn\u001b[39;00m _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)\n",
      "File \u001b[0;32m~/ua/4-2/mdle/venv/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:369\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[1;32m    366\u001b[0m     distances \u001b[39m=\u001b[39m _euclidean_distances_upcast(X, XX, Y, YY)\n\u001b[1;32m    367\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    368\u001b[0m     \u001b[39m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m     distances \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m safe_sparse_dot(X, Y\u001b[39m.\u001b[39;49mT, dense_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    370\u001b[0m     distances \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m XX\n\u001b[1;32m    371\u001b[0m     distances \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m YY\n",
      "File \u001b[0;32m~/ua/4-2/mdle/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:189\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    187\u001b[0m         ret \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(a, b)\n\u001b[1;32m    188\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     ret \u001b[39m=\u001b[39m a \u001b[39m@\u001b[39;49m b\n\u001b[1;32m    191\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    192\u001b[0m     sparse\u001b[39m.\u001b[39missparse(a)\n\u001b[1;32m    193\u001b[0m     \u001b[39mand\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(b)\n\u001b[1;32m    194\u001b[0m     \u001b[39mand\u001b[39;00m dense_output\n\u001b[1;32m    195\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(ret, \u001b[39m\"\u001b[39m\u001b[39mtoarray\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    196\u001b[0m ):\n\u001b[1;32m    197\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\u001b[39m.\u001b[39mtoarray()\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 58.0 GiB for an array with shape (88234, 88234) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "# SpectralClustering(n_clusters_ideal, eigen_solver='lobpcg').fit(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Power Iteration Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/21 20:26:53 WARN Utils: Your hostname, martinho-MS-7B86 resolves to a loopback address: 127.0.1.1; using 192.168.1.67 instead (on interface enp34s0)\n",
      "23/05/21 20:26:53 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/21 20:26:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import PowerIterationClustering\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('SpectralClustering') \\\n",
    "    .config('spark.master', 'local[*]') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_spark = spark.createDataFrame(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the weight column (all at 1s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_spark = dataset_spark.withColumn('weight', F.lit(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|  id|cluster|\n",
      "+----+-------+\n",
      "|2340|      1|\n",
      "|3984|      0|\n",
      "|3588|      0|\n",
      "|1260|      0|\n",
      "|3456|      0|\n",
      "| 324|      0|\n",
      "| 180|      0|\n",
      "|1080|      0|\n",
      "|2076|      1|\n",
      "|2412|      1|\n",
      "| 744|      0|\n",
      "| 408|      0|\n",
      "|2436|      1|\n",
      "| 996|      1|\n",
      "|3468|      0|\n",
      "|3528|      0|\n",
      "|1740|      0|\n",
      "| 480|      0|\n",
      "|  24|      0|\n",
      "| 912|      1|\n",
      "+----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pic = PowerIterationClustering(k=2, maxIter=20, initMode=\"degree\", srcCol='0', dstCol='1', weightCol=\"weight\")\n",
    "pic.assignClusters(dataset_spark).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
